{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yzI0dRW-0Fn3",
    "outputId": "8c3e1373-d838-4c22-dfd9-f0ceddbf93ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\arvee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "ZrmgKttB0Y3F",
    "outputId": "12c718f2-f9bd-4f5c-ada0-f1f5c84bd0af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is my book</td>\n",
       "      <td>stmt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They are novels</td>\n",
       "      <td>stmt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>have you read this book</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who is the author</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what are the characters</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This is how I bought the book</td>\n",
       "      <td>stmt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I like fictions</td>\n",
       "      <td>stmt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what is your favorite book</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            sent     class\n",
       "0                This is my book      stmt\n",
       "1                They are novels      stmt\n",
       "2        have you read this book  question\n",
       "3              who is the author  question\n",
       "4        what are the characters  question\n",
       "5  This is how I bought the book      stmt\n",
       "6                I like fictions      stmt\n",
       "7     what is your favorite book  question"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['sent', 'class']\n",
    "rows = []\n",
    "\n",
    "rows = [['This is my book', 'stmt'], \n",
    "        ['They are novels', 'stmt'],\n",
    "        ['have you read this book', 'question'],\n",
    "        ['who is the author', 'question'],\n",
    "        ['what are the characters', 'question'],\n",
    "        ['This is how I bought the book', 'stmt'],\n",
    "        ['I like fictions', 'stmt'],\n",
    "        ['what is your favorite book', 'question']]\n",
    "\n",
    "training_data = pd.DataFrame(rows, columns=columns)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "id": "bju8hDJe0fx5",
    "outputId": "23aaf806-ed5d-4ee5-fb19-e367d19a5640"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>are</th>\n",
       "      <th>book</th>\n",
       "      <th>bought</th>\n",
       "      <th>fictions</th>\n",
       "      <th>how</th>\n",
       "      <th>is</th>\n",
       "      <th>like</th>\n",
       "      <th>my</th>\n",
       "      <th>novels</th>\n",
       "      <th>the</th>\n",
       "      <th>they</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   are  book  bought  fictions  how  is  like  my  novels  the  they  this\n",
       "0    0     1       0         0    0   1     0   1       0    0     0     1\n",
       "1    1     0       0         0    0   0     0   0       1    0     1     0\n",
       "2    0     1       1         0    1   1     0   0       0    1     0     1\n",
       "3    0     0       0         1    0   0     1   0       0    0     0     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stmt_docs = [row['sent'] for index,row in training_data.iterrows() if row['class'] == 'stmt']\n",
    "\n",
    "vec_s = CountVectorizer()\n",
    "X_s = vec_s.fit_transform(stmt_docs)\n",
    "tdm_s = pd.DataFrame(X_s.toarray(), columns=vec_s.get_feature_names())\n",
    "\n",
    "tdm_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "id": "rELGLhd10ztF",
    "outputId": "000bc1ee-53d4-4bd5-86d2-c3f4db5cb022"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>are</th>\n",
       "      <th>author</th>\n",
       "      <th>book</th>\n",
       "      <th>characters</th>\n",
       "      <th>favorite</th>\n",
       "      <th>have</th>\n",
       "      <th>is</th>\n",
       "      <th>read</th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "      <th>what</th>\n",
       "      <th>who</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   are  author  book  characters  favorite  have  is  read  the  this  what  \\\n",
       "0    0       0     1           0         0     1   0     1    0     1     0   \n",
       "1    0       1     0           0         0     0   1     0    1     0     0   \n",
       "2    1       0     0           1         0     0   0     0    1     0     1   \n",
       "3    0       0     1           0         1     0   1     0    0     0     1   \n",
       "\n",
       "   who  you  your  \n",
       "0    0    1     0  \n",
       "1    1    0     0  \n",
       "2    0    0     0  \n",
       "3    0    0     1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_docs = [row['sent'] for index,row in training_data.iterrows() if row['class'] == 'question']\n",
    "\n",
    "vec_q = CountVectorizer()\n",
    "X_q = vec_q.fit_transform(q_docs)\n",
    "tdm_q = pd.DataFrame(X_q.toarray(), columns=vec_q.get_feature_names())\n",
    "\n",
    "tdm_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hqvYPJQE01sU",
    "outputId": "926bf85c-c020-4c59-a79e-d3944e6aa34b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'are': 1,\n",
       " 'book': 2,\n",
       " 'bought': 1,\n",
       " 'fictions': 1,\n",
       " 'how': 1,\n",
       " 'is': 2,\n",
       " 'like': 1,\n",
       " 'my': 1,\n",
       " 'novels': 1,\n",
       " 'the': 1,\n",
       " 'they': 1,\n",
       " 'this': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list_s = vec_s.get_feature_names();    \n",
    "count_list_s = X_s.toarray().sum(axis=0) \n",
    "freq_s = dict(zip(word_list_s,count_list_s))\n",
    "freq_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQjTCxxb05av",
    "outputId": "8aa86275-2379-4cb2-dbe4-e436852702c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'are': 1,\n",
       " 'author': 1,\n",
       " 'book': 2,\n",
       " 'characters': 1,\n",
       " 'favorite': 1,\n",
       " 'have': 1,\n",
       " 'is': 2,\n",
       " 'read': 1,\n",
       " 'the': 2,\n",
       " 'this': 1,\n",
       " 'what': 2,\n",
       " 'who': 1,\n",
       " 'you': 1,\n",
       " 'your': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list_q = vec_q.get_feature_names();    \n",
    "count_list_q = X_q.toarray().sum(axis=0) \n",
    "freq_q = dict(zip(word_list_q,count_list_q))\n",
    "freq_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v0oVuG221LSr",
    "outputId": "95767681-2ddc-4964-b5db-d3e979b18530"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'are': 0.08333333333333333,\n",
       " 'book': 0.16666666666666666,\n",
       " 'bought': 0.08333333333333333,\n",
       " 'fictions': 0.08333333333333333,\n",
       " 'how': 0.08333333333333333,\n",
       " 'is': 0.16666666666666666,\n",
       " 'like': 0.08333333333333333,\n",
       " 'my': 0.08333333333333333,\n",
       " 'novels': 0.08333333333333333,\n",
       " 'the': 0.08333333333333333,\n",
       " 'they': 0.08333333333333333,\n",
       " 'this': 0.16666666666666666}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_s = []\n",
    "for word,count in zip(word_list_s, count_list_s):\n",
    "    prob_s.append(count/len(word_list_s))\n",
    "dict(zip(word_list_s, prob_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dH4shgkI2Cd0",
    "outputId": "f90f8de6-af59-4eb8-907b-677bf5a39df0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'are': 0.07142857142857142,\n",
       " 'author': 0.07142857142857142,\n",
       " 'book': 0.14285714285714285,\n",
       " 'characters': 0.07142857142857142,\n",
       " 'favorite': 0.07142857142857142,\n",
       " 'have': 0.07142857142857142,\n",
       " 'is': 0.14285714285714285,\n",
       " 'read': 0.07142857142857142,\n",
       " 'the': 0.14285714285714285,\n",
       " 'this': 0.07142857142857142,\n",
       " 'what': 0.14285714285714285,\n",
       " 'who': 0.07142857142857142,\n",
       " 'you': 0.07142857142857142,\n",
       " 'your': 0.07142857142857142}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_q = []\n",
    "for count in count_list_q:\n",
    "    prob_q.append(count/len(word_list_q))\n",
    "dict(zip(word_list_q, prob_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4iEm2aB62Z_a",
    "outputId": "49ebb4dd-141b-4d12-a5b8-affd06c45149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "docs = [row['sent'] for index,row in training_data.iterrows()]\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(docs)\n",
    "\n",
    "total_features = len(vec.get_feature_names())\n",
    "total_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tIfrmhhZ2hLr",
    "outputId": "c63d1d5e-a130-4609-e2a9-eaaa613e8c0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "total_cnts_features_s = count_list_s.sum(axis=0)\n",
    "total_cnts_features_q = count_list_q.sum(axis=0)\n",
    "\n",
    "print(total_cnts_features_q)\n",
    "print(total_cnts_features_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ANKrxeEO2hw0"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "new_sentence = 'what is the price of the book'\n",
    "new_word_list = word_tokenize(new_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lekhdXiH2_R-",
    "outputId": "59e78dec-3a06-47aa-d808-d3ea549ab529"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'what': 0.027777777777777776, 'is': 0.08333333333333333, 'the': 0.05555555555555555, 'price': 0.027777777777777776, 'of': 0.027777777777777776, 'book': 0.08333333333333333}\n"
     ]
    }
   ],
   "source": [
    "prob_s_with_ls = []\n",
    "for word in new_word_list:\n",
    "    if word in freq_s.keys():\n",
    "        count = freq_s[word]\n",
    "    else:\n",
    "        count = 0\n",
    "    prob_s_with_ls.append((count + 1)/(total_cnts_features_s + total_features))\n",
    "stmt_prob = dict(zip(new_word_list,prob_s_with_ls))\n",
    "print(stmt_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2QhPbjX83nMq",
    "outputId": "d2ad2952-e380-4f4e-dc41-87720b31a3e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'what': 0.07692307692307693, 'is': 0.07692307692307693, 'the': 0.07692307692307693, 'price': 0.02564102564102564, 'of': 0.02564102564102564, 'book': 0.07692307692307693}\n"
     ]
    }
   ],
   "source": [
    "prob_q_with_ls = []\n",
    "for word in new_word_list:\n",
    "    if word in freq_q.keys():\n",
    "        count = freq_q[word]\n",
    "    else:\n",
    "        count = 0\n",
    "    prob_q_with_ls.append((count + 1)/(total_cnts_features_q + total_features))\n",
    "quest_prob = dict(zip(new_word_list,prob_q_with_ls))\n",
    "print(quest_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1JqrxUTM3tG7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', 'the', 'price', 'of', 'the', 'book']\n",
      "P(What is the price of the book|Question) =  1.7707368464359263e-09\n",
      "P(What is the price of the book|Stmt) =  4.5939365799778324e-10\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "sentence = \"What is the price of the book?\"\n",
    "sentence = sentence.lower()\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "new_words = tokenizer.tokenize(sentence)\n",
    "print(new_words)\n",
    "prob_quest = 1\n",
    "prob_stmt = 1\n",
    "for word in new_words:\n",
    "    prob_quest *= quest_prob[word]\n",
    "    prob_stmt *= stmt_prob[word]\n",
    "print(\"P(What is the price of the book|Question) = \",prob_quest)\n",
    "print(\"P(What is the price of the book|Stmt) = \",prob_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Stmt|What is the price of the book) = P(what is the price of the book|Stmt)*P(Stmt)\n",
      "P(Stmt|What is the price of the book) =  2.2969682899889162e-10\n"
     ]
    }
   ],
   "source": [
    "print(\"P(Stmt|What is the price of the book) = P(what is the price of the book|Stmt)*P(Stmt)\")\n",
    "print(\"P(Stmt|What is the price of the book) = \",prob_stmt*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Question|What is the price of the book) = P(what is the price of the book|Question)*P(Question)\n",
      "P(Question|What is the price of the book) =  8.853684232179632e-10\n"
     ]
    }
   ],
   "source": [
    "print(\"P(Question|What is the price of the book) = P(what is the price of the book|Question)*P(Question)\")\n",
    "print(\"P(Question|What is the price of the book) = \",prob_quest*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Therefore the new sentence ‘What is the price of the book’ will be classified as ‘Question’\n"
     ]
    }
   ],
   "source": [
    "assert(prob_quest>prob_stmt)\n",
    "print(\"Therefore the new sentence ‘What is the price of the book’ will be classified as ‘Question’\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP-Exp-6_Text Classification using Naive Bayes Classifier._B250.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
